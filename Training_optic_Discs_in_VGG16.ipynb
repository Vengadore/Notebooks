{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Training_optic_Discs_in_VGG16.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "58898cf57b184567b20d7f061f690b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_29d3df2d21ee475e811b82309eb0c3eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aaa565567d784b599e27ad1b8f7e85bd",
              "IPY_MODEL_ef291f7ff1fd477b9575f776a2ba447f"
            ]
          }
        },
        "29d3df2d21ee475e811b82309eb0c3eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aaa565567d784b599e27ad1b8f7e85bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a1a5ccef2005492ab77270b94b8a77c1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ba4149a3f58489a931dcdd22c702d38"
          }
        },
        "ef291f7ff1fd477b9575f776a2ba447f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_162732b4416c4362904e41a138f9532d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:06&lt;00:00, 85.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_795e1ac22ab5405eaeb6642ca3ca7ef7"
          }
        },
        "a1a5ccef2005492ab77270b94b8a77c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ba4149a3f58489a931dcdd22c702d38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "162732b4416c4362904e41a138f9532d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "795e1ac22ab5405eaeb6642ca3ca7ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vengadore/Notebooks/blob/master/Training_optic_Discs_in_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVm5Ats_YVEZ"
      },
      "source": [
        "# Diabetic Retinopathy Detection\n",
        "\n",
        "Kaggle has a large competition of Diabetic Retinopathy detection which can be found here:\n",
        "https://www.kaggle.com/c/diabetic-retinopathy-detection/\n",
        "\n",
        "Their dataset consists in 35126 images labeled from 0 to 4 according to the degree of Retinopathy.\n",
        "An analysis of the data is provided in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QABUN5czaGrr",
        "outputId": "67548176-334f-4d7d-817c-3e4c2d471852"
      },
      "source": [
        "!rm -rf sample_data\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Feb 18 13:34:24 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrtmQaiBbcy5"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKfg7kcTbb4h"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install efficientnet_pytorch\n",
        "clear_output(wait=False)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO_cEyuIeDjq"
      },
      "source": [
        "## Load data from local drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWk0Ox2ueHNB",
        "outputId": "f5fb66ff-b1fc-4467-a2d7-b3eb85a99229"
      },
      "source": [
        "!wget -O File.zip \"https://correoipn-my.sharepoint.com/:u:/g/personal/ccarrillog1400_alumno_ipn_mx/ETdcB8GscyBAkhUFvNMzpoUBLLgg7ej9Q3t4rK_bR8ngSA?download=1\"\n",
        "!unzip File.zip\n",
        "!rm File.zip\n",
        "clear_output(wait=False)\n",
        "print(\"Data Downloaded\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUCY7oQLorC9",
        "outputId": "05291a24-e171-4a4b-999a-a04c50e4b0ce"
      },
      "source": [
        "!rm checkpoint*"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'checkpoint*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dNqkjvcUetED",
        "outputId": "56d4da12-57ca-4dfe-8130-7c57810557b4"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "Bad =  pd.DataFrame({\"imageFilename\":[os.path.join(\"./OpticDiscs/Neovessels\",File) for File in os.listdir(\"./OpticDiscs/Neovessels\") if \".jpeg\" in File]})\n",
        "Good = pd.DataFrame({\"imageFilename\":[os.path.join(\"./OpticDiscs/Good images\",File) for File in os.listdir(\"./OpticDiscs/Good images\") if \".jpeg\" in File]}).sample(len(Bad),random_state = 42)\n",
        "\n",
        "data = pd.concat((Good,Bad),axis = 0)\n",
        "data.head()\n",
        "data['class'] = data['imageFilename'].apply(lambda x : 1 if \"Good\" in x else 0)\n",
        "data = data.reset_index()\n",
        "data = data[['imageFilename','class']]\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imageFilename</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./OpticDiscs/Good images/18823_left.jpeg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./OpticDiscs/Good images/26309_right.jpeg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./OpticDiscs/Good images/8040_left.jpeg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./OpticDiscs/Good images/23981_left.jpeg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./OpticDiscs/Good images/29043_left.jpeg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               imageFilename  class\n",
              "0   ./OpticDiscs/Good images/18823_left.jpeg      1\n",
              "1  ./OpticDiscs/Good images/26309_right.jpeg      1\n",
              "2    ./OpticDiscs/Good images/8040_left.jpeg      1\n",
              "3   ./OpticDiscs/Good images/23981_left.jpeg      1\n",
              "4   ./OpticDiscs/Good images/29043_left.jpeg      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3N0Ue5MCvlk",
        "outputId": "cf90aeb6-b003-404c-8e59-64257b03f2ac"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "374"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deKSOu-Kd8Yk"
      },
      "source": [
        "#### Split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w3TUlaqd7qi"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['imageFilename'], data['class'], test_size=0.40, random_state=65)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3hQn37YfvsA",
        "outputId": "8d2c29e3-8e82-4d52-ad4c-a5b4b9ad7ed5"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    119\n",
              "1    105\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nVIy3dn7eKFq",
        "outputId": "e7d8b44a-4673-4061-f598-ee4274556f68"
      },
      "source": [
        "test_data = pd.DataFrame({'image':X_test,'class':y_test})\n",
        "test_data['image'] = test_data['image'].apply(lambda x : x.split('/')[-1])\n",
        "test_data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>19285_right.jpeg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>11874_right.jpeg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>10047_right.jpeg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>35955_left.jpeg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>26930_left.jpeg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                image  class\n",
              "278  19285_right.jpeg      0\n",
              "366  11874_right.jpeg      0\n",
              "287  10047_right.jpeg      0\n",
              "202   35955_left.jpeg      0\n",
              "146   26930_left.jpeg      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YsYT7VjerXq"
      },
      "source": [
        "test_data.to_csv('test_data.csv',index=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPh3qDdIdkHh"
      },
      "source": [
        "## Definition of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-FUmuJidoy3",
        "outputId": "e7013e39-72f3-4b41-fc38-589a333201b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "58898cf57b184567b20d7f061f690b97",
            "29d3df2d21ee475e811b82309eb0c3eb",
            "aaa565567d784b599e27ad1b8f7e85bd",
            "ef291f7ff1fd477b9575f776a2ba447f",
            "a1a5ccef2005492ab77270b94b8a77c1",
            "1ba4149a3f58489a931dcdd22c702d38",
            "162732b4416c4362904e41a138f9532d",
            "795e1ac22ab5405eaeb6642ca3ca7ef7"
          ]
        }
      },
      "source": [
        "import torchvision.models as models\n",
        "import torch\n",
        "network_name = 'VGG16'\n",
        "model = models.vgg16(pretrained = True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58898cf57b184567b20d7f061f690b97",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drpW39Qwj3l9",
        "outputId": "7ef724bb-96ce-4a11-ee95-5922ea179f09"
      },
      "source": [
        "model.classifier[-1]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=4096, out_features=1000, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu_aoH7-tBsT"
      },
      "source": [
        "## Change efficientnet final layer\n",
        "model.classifier[-1] = torch.nn.Linear(in_features=4096,out_features=2,bias = True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNns-LOy6TrK",
        "outputId": "91ee9f17-2ad4-493f-9303-16f7618fb3cc"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "count_parameters(model)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "134268738"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BR_Hs12gAqx"
      },
      "source": [
        "from torchvision.transforms import Resize,ToTensor,Compose,Normalize\n",
        "from torchvision.transforms import RandomHorizontalFlip,RandomVerticalFlip,RandomRotation,ColorJitter\n",
        "from PIL import Image\n",
        "\n",
        "transforms = Compose([RandomHorizontalFlip(),RandomVerticalFlip(),RandomRotation(180),ColorJitter(0.5,0.5,0.5)]) # Transformations for the training images\n",
        "\n",
        "composed = Compose([Resize(224), # Resize to a fit size for efficientnet\n",
        "                    ToTensor(),  # Convert into sensor\n",
        "                    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # Normalize image"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWg1p7EQtqVZ"
      },
      "source": [
        "### Training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiT-MlPutsZR"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device);\n",
        "seed = 17\n",
        "torch.manual_seed(seed)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJWflI4JoVRW",
        "outputId": "b4ce7dcf-57f3-49ad-e76a-1ffb6ba65ff4"
      },
      "source": [
        "try:\n",
        "    model = torch.load('./checkpoint_b0_11.ph', map_location=device)\n",
        "except:\n",
        "    print(\"No Checkpoint loaded\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No Checkpoint loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcTzzyr5uUdr"
      },
      "source": [
        "classes = {0:[0,0,0,0,1],\n",
        "           1:[0,0,0,1,0],\n",
        "           2:[0,0,1,0,0],\n",
        "           3:[0,1,0,0,0],\n",
        "           4:[1,0,0,0,0]}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkvlQWRQtjXo",
        "outputId": "9088f9f0-1937-41db-f46f-c96212cde585"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "random.seed(seed)\n",
        "\n",
        "epochs = 40\n",
        "batch_size = 1  # I will use batch size of 1 to keep the ratio of each image\n",
        "\n",
        "TRAINING_acc = []\n",
        "VALIDATION_acc = []\n",
        "BEST_val_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    indexes = [idx for idx in range(len(X_train))]\n",
        "    pbar = tqdm( range(len(X_train)//batch_size),ncols = 100)\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    t = 0\n",
        "\n",
        "    for step in pbar:\n",
        "        # Load data\n",
        "        idx = random.sample(indexes,batch_size)\n",
        "        X = X_train.iloc[idx]\n",
        "        y = y_train.iloc[idx]\n",
        "\n",
        "        # Remove indexes\n",
        "        [indexes.remove(i) for i in idx]\n",
        "\n",
        "        # Load images\n",
        "        try:\n",
        "            images = [Image.open(File) for File in X]\n",
        "        except:\n",
        "            continue\n",
        "        # Load y_true\n",
        "        y_true = torch.LongTensor([c for c in y]).to(device)\n",
        "        \n",
        "        # Convert images to tensor\n",
        "        x_batch = torch.FloatTensor().to(device)\n",
        "        for image in images:\n",
        "            P = transforms(image)\n",
        "            P = composed(P).unsqueeze(0).to(device)\n",
        "            x_batch = torch.cat((x_batch,P))\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(x_batch)\n",
        "        loss = criterion(outputs, y_true)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        t += batch_size\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_acc += torch.sum(preds == y_true).cpu().detach().numpy()\n",
        "        acc = torch.sum(preds == y_true).cpu().detach().numpy()/batch_size;\n",
        "        pbar.set_description(\"Epoch: {} Accuracy: {:0.5f} Loss: {:0.5f} \".format(epoch+1,running_acc/t,loss.item()))\n",
        "    #Validation\n",
        "    TRAINING_acc.append(running_acc/t)\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "    t = 0\n",
        "    for point in range(len(X_test)//batch_size):\n",
        "        with torch.no_grad():\n",
        "\n",
        "            X = X_test.iloc[point*batch_size:(point+1)*batch_size]\n",
        "            y = y_test.iloc[point*batch_size:(point+1)*batch_size]\n",
        "\n",
        "\n",
        "            # Load images\n",
        "            try:\n",
        "                images = [Image.open(File) for File in X]\n",
        "            except:\n",
        "                continue\n",
        "            # Load y_true\n",
        "            y_true = torch.LongTensor([c for c in y]).to(device)\n",
        "            \n",
        "            # Convert images to tensor\n",
        "            x_batch = torch.FloatTensor().to(device)\n",
        "            for image in images:\n",
        "                P = composed(image).unsqueeze(0).to(device)\n",
        "                x_batch = torch.cat((x_batch,P))\n",
        "\n",
        "            \n",
        "            outputs = model(x_batch)\n",
        "            loss = criterion(outputs, y_true)\n",
        "            val_loss += loss.item()\n",
        "            t += batch_size\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_acc += torch.sum(preds == y_true).cpu().detach().numpy()\n",
        "    VALIDATION_acc.append(val_acc/t)\n",
        "    print(\"Validation -- Accuracy: {:0.5f} Loss: {:0.5f} \\n\".format(val_acc/t,loss.item()))\n",
        "    if val_acc/t > BEST_val_acc:\n",
        "        try:\n",
        "            torch.save(model,\"/content/checkpoint_{}_{}_{:0.5f}.ph\".format(network_name,epoch+1,val_acc/t))\n",
        "            BEST_val_acc = val_acc/t\n",
        "        except:\n",
        "            continue"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Accuracy: 0.54464 Loss: 0.52347 : 100%|██████████████████| 224/224 [00:27<00:00,  8.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.44000 Loss: 0.75593 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2 Accuracy: 0.52232 Loss: 0.54977 : 100%|██████████████████| 224/224 [00:27<00:00,  8.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.52667 Loss: 0.75839 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3 Accuracy: 0.62500 Loss: 0.54382 : 100%|██████████████████| 224/224 [00:27<00:00,  8.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.63333 Loss: 0.63476 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4 Accuracy: 0.67411 Loss: 0.53804 : 100%|██████████████████| 224/224 [00:27<00:00,  8.22it/s]\n",
            "Epoch: 5 Accuracy: 1.00000 Loss: 0.37898 :   0%|                    | 1/224 [00:00<00:23,  9.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.61333 Loss: 0.69688 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5 Accuracy: 0.72321 Loss: 0.60783 : 100%|██████████████████| 224/224 [00:27<00:00,  8.23it/s]\n",
            "Epoch: 6 Accuracy: 1.00000 Loss: 0.28666 :   0%|                            | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.60667 Loss: 0.67685 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6 Accuracy: 0.73214 Loss: 0.58578 : 100%|██████████████████| 224/224 [00:27<00:00,  8.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.71333 Loss: 0.63099 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7 Accuracy: 0.74554 Loss: 0.13554 : 100%|██████████████████| 224/224 [00:27<00:00,  8.18it/s]\n",
            "Epoch: 8 Accuracy: 1.00000 Loss: 0.24702 :   0%|                    | 1/224 [00:00<00:38,  5.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.71333 Loss: 0.52156 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8 Accuracy: 0.80804 Loss: 1.04606 : 100%|██████████████████| 224/224 [00:27<00:00,  8.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.77333 Loss: 0.59492 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9 Accuracy: 0.80804 Loss: 0.14531 : 100%|██████████████████| 224/224 [00:27<00:00,  8.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.78000 Loss: 0.32365 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10 Accuracy: 0.79911 Loss: 0.53639 : 100%|█████████████████| 224/224 [00:27<00:00,  8.18it/s]\n",
            "Epoch: 11 Accuracy: 1.00000 Loss: 0.14921 :   0%|                   | 1/224 [00:00<00:24,  9.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.78000 Loss: 0.21806 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11 Accuracy: 0.81696 Loss: 0.15440 : 100%|█████████████████| 224/224 [00:27<00:00,  8.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.80000 Loss: 0.17985 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12 Accuracy: 0.83036 Loss: 0.43525 : 100%|█████████████████| 224/224 [00:27<00:00,  8.17it/s]\n",
            "Epoch: 13 Accuracy: 1.00000 Loss: 0.06017 :   0%|                   | 1/224 [00:00<00:25,  8.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.79333 Loss: 0.08066 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13 Accuracy: 0.83929 Loss: 2.75297 : 100%|█████████████████| 224/224 [00:27<00:00,  8.23it/s]\n",
            "Epoch: 14 Accuracy: 1.00000 Loss: 0.10882 :   0%|                   | 1/224 [00:00<00:26,  8.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.79333 Loss: 0.12354 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14 Accuracy: 0.83482 Loss: 0.93593 : 100%|█████████████████| 224/224 [00:27<00:00,  8.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.82667 Loss: 0.15403 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15 Accuracy: 0.84821 Loss: 0.65867 : 100%|█████████████████| 224/224 [00:27<00:00,  8.18it/s]\n",
            "Epoch: 16 Accuracy: 1.00000 Loss: 0.11968 :   0%|                   | 1/224 [00:00<00:35,  6.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.81333 Loss: 0.13852 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 16 Accuracy: 0.89286 Loss: 0.00459 : 100%|█████████████████| 224/224 [00:27<00:00,  8.23it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.83333 Loss: 0.05186 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 17 Accuracy: 0.88839 Loss: 0.01524 : 100%|█████████████████| 224/224 [00:27<00:00,  8.14it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.85333 Loss: 0.03431 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 18 Accuracy: 0.89732 Loss: 0.07627 : 100%|█████████████████| 224/224 [00:27<00:00,  8.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.86000 Loss: 0.06410 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 19 Accuracy: 0.90625 Loss: 0.05121 : 100%|█████████████████| 224/224 [00:27<00:00,  8.21it/s]\n",
            "Epoch: 20 Accuracy: 1.00000 Loss: 0.07105 :   0%|                   | 1/224 [00:00<00:31,  7.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.81333 Loss: 0.06483 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 20 Accuracy: 0.91964 Loss: 0.00173 : 100%|█████████████████| 224/224 [00:27<00:00,  8.13it/s]\n",
            "Epoch: 21 Accuracy: 1.00000 Loss: 0.00108 :   1%|▏                  | 2/224 [00:00<00:21, 10.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.84000 Loss: 0.07342 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 21 Accuracy: 0.90179 Loss: 0.13359 : 100%|█████████████████| 224/224 [00:27<00:00,  8.07it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.87333 Loss: 0.01318 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 22 Accuracy: 0.91071 Loss: 0.09817 : 100%|█████████████████| 224/224 [00:27<00:00,  8.11it/s]\n",
            "Epoch: 23 Accuracy: 1.00000 Loss: 0.00918 :   0%|                   | 1/224 [00:00<00:26,  8.53it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.86667 Loss: 0.06195 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 23 Accuracy: 0.91071 Loss: 0.00395 : 100%|█████████████████| 224/224 [00:27<00:00,  8.18it/s]\n",
            "Epoch: 24 Accuracy: 1.00000 Loss: 0.12832 :   0%|                   | 1/224 [00:00<00:24,  8.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.84667 Loss: 0.10359 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 24 Accuracy: 0.91071 Loss: 0.01170 : 100%|█████████████████| 224/224 [00:27<00:00,  8.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.88667 Loss: 0.04336 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 25 Accuracy: 0.92411 Loss: 0.15265 : 100%|█████████████████| 224/224 [00:27<00:00,  8.15it/s]\n",
            "Epoch: 26 Accuracy: 1.00000 Loss: 0.00053 :   0%|                   | 1/224 [00:00<00:23,  9.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.84667 Loss: 0.10701 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 26 Accuracy: 0.95089 Loss: 0.00684 : 100%|█████████████████| 224/224 [00:27<00:00,  8.18it/s]\n",
            "Epoch: 27 Accuracy: 1.00000 Loss: 0.27203 :   0%|                   | 1/224 [00:00<00:24,  8.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.86000 Loss: 0.02594 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 27 Accuracy: 0.92857 Loss: 0.12453 : 100%|█████████████████| 224/224 [00:27<00:00,  8.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.90667 Loss: 0.02502 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 28 Accuracy: 0.91964 Loss: 0.35425 : 100%|█████████████████| 224/224 [00:27<00:00,  8.17it/s]\n",
            "Epoch: 29 Accuracy: 1.00000 Loss: 0.00299 :   0%|                   | 1/224 [00:00<00:27,  8.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.88000 Loss: 0.01775 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 29 Accuracy: 0.94643 Loss: 0.01953 : 100%|█████████████████| 224/224 [00:27<00:00,  8.23it/s]\n",
            "Epoch: 30 Accuracy: 1.00000 Loss: 0.02021 :   0%|                   | 1/224 [00:00<00:36,  6.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.87333 Loss: 0.05751 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 30 Accuracy: 0.93750 Loss: 0.00245 : 100%|█████████████████| 224/224 [00:27<00:00,  8.20it/s]\n",
            "Epoch: 31 Accuracy: 1.00000 Loss: 0.14977 :   0%|                   | 1/224 [00:00<00:30,  7.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.85333 Loss: 0.11123 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 31 Accuracy: 0.95536 Loss: 0.00041 : 100%|█████████████████| 224/224 [00:27<00:00,  8.21it/s]\n",
            "Epoch: 32 Accuracy: 1.00000 Loss: 0.32639 :   0%|                   | 1/224 [00:00<00:26,  8.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.83333 Loss: 0.03978 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 32 Accuracy: 0.93304 Loss: 0.04663 : 100%|█████████████████| 224/224 [00:27<00:00,  8.22it/s]\n",
            "Epoch: 33 Accuracy: 1.00000 Loss: 0.10238 :   0%|                   | 1/224 [00:00<00:27,  8.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.86667 Loss: 0.04546 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 33 Accuracy: 0.94643 Loss: 0.08565 : 100%|█████████████████| 224/224 [00:27<00:00,  8.20it/s]\n",
            "Epoch: 34 Accuracy: 1.00000 Loss: 0.05522 :   0%|                   | 1/224 [00:00<00:29,  7.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.86667 Loss: 0.02833 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 34 Accuracy: 0.95536 Loss: 0.00039 : 100%|█████████████████| 224/224 [00:27<00:00,  8.23it/s]\n",
            "Epoch: 35 Accuracy: 1.00000 Loss: 0.17169 :   0%|                   | 1/224 [00:00<00:26,  8.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.89333 Loss: 0.01070 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 35 Accuracy: 0.95089 Loss: 0.09851 : 100%|█████████████████| 224/224 [00:27<00:00,  8.27it/s]\n",
            "Epoch: 36 Accuracy: 1.00000 Loss: 0.00010 :   0%|                   | 1/224 [00:00<00:24,  9.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.86667 Loss: 0.04754 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 36 Accuracy: 0.95536 Loss: 0.01246 : 100%|█████████████████| 224/224 [00:27<00:00,  8.25it/s]\n",
            "Epoch: 37 Accuracy: 1.00000 Loss: 0.01284 :   1%|▏                  | 2/224 [00:00<00:21, 10.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.88667 Loss: 0.01117 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 37 Accuracy: 0.95982 Loss: 0.01044 : 100%|█████████████████| 224/224 [00:27<00:00,  8.25it/s]\n",
            "Epoch: 38 Accuracy: 1.00000 Loss: 0.00084 :   0%|                   | 1/224 [00:00<00:26,  8.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.86667 Loss: 0.02999 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 38 Accuracy: 0.95982 Loss: 0.00185 : 100%|█████████████████| 224/224 [00:27<00:00,  8.26it/s]\n",
            "Epoch: 39 Accuracy: 1.00000 Loss: 0.00195 :   0%|                   | 1/224 [00:00<00:30,  7.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.87333 Loss: 0.01343 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 39 Accuracy: 0.96429 Loss: 0.07807 : 100%|█████████████████| 224/224 [00:27<00:00,  8.25it/s]\n",
            "Epoch: 40 Accuracy: 1.00000 Loss: 0.00018 :   0%|                   | 1/224 [00:00<00:31,  7.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.87333 Loss: 0.00770 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 40 Accuracy: 0.95982 Loss: 0.06991 : 100%|█████████████████| 224/224 [00:27<00:00,  8.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.86667 Loss: 0.01868 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "rpupTOMPlWD8",
        "outputId": "99ad3b55-d275-4d9f-b6af-e874d35f6918"
      },
      "source": [
        "history = pd.DataFrame({\"Train\":TRAINING_acc,\"Validation\":VALIDATION_acc})\n",
        "history.plot()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b88b71358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PV_uLtQnaO4",
        "outputId": "cc932938-c29e-45de-919d-6f3bc5936f95"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint_VGG16_1_0.44000.ph\tcheckpoint_VGG16_24_0.88667.ph\n",
            "checkpoint_VGG16_11_0.80000.ph\tcheckpoint_VGG16_27_0.90667.ph\n",
            "checkpoint_VGG16_14_0.82667.ph\tcheckpoint_VGG16_3_0.63333.ph\n",
            "checkpoint_VGG16_16_0.83333.ph\tcheckpoint_VGG16_6_0.71333.ph\n",
            "checkpoint_VGG16_17_0.85333.ph\tcheckpoint_VGG16_8_0.77333.ph\n",
            "checkpoint_VGG16_18_0.86000.ph\tcheckpoint_VGG16_9_0.78000.ph\n",
            "checkpoint_VGG16_2_0.52667.ph\tOpticDiscs\n",
            "checkpoint_VGG16_21_0.87333.ph\ttest_data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VumKHi2Snf4F"
      },
      "source": [
        "torch.save(model,\"checkpoint.ph\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYI16QYGyqLF",
        "outputId": "02f7e39e-4cc1-4c2f-b815-3e5972885e7b"
      },
      "source": [
        "for c in y:\n",
        "  print(c)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv2fODvHJlIM"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ennB90UVVmb"
      },
      "source": [
        "model = torch.load('checkpoint_VGG16_27_0.90667.ph')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLd2H4FrJnXo"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6nVWUqYJoDh"
      },
      "source": [
        "predicted = []\n",
        "true_values = []\n",
        "for point in range(len(X_test)//batch_size):\n",
        "    with torch.no_grad():\n",
        "\n",
        "        X = X_test.iloc[point*batch_size:(point+1)*batch_size]\n",
        "        y = y_test.iloc[point*batch_size:(point+1)*batch_size]\n",
        "\n",
        "        true_values.append(y.values)\n",
        "        # Load images\n",
        "        try:\n",
        "            images = [Image.open(File) for File in X]\n",
        "        except:\n",
        "            continue\n",
        "        # Load y_true\n",
        "        y_true = torch.LongTensor([c for c in y]).to(device)\n",
        "        \n",
        "        # Convert images to tensor\n",
        "        x_batch = torch.FloatTensor().to(device)\n",
        "        for image in images:\n",
        "            P = composed(image).unsqueeze(0).to(device)\n",
        "            x_batch = torch.cat((x_batch,P))\n",
        "\n",
        "        \n",
        "        outputs = model(x_batch)\n",
        "        loss = criterion(outputs, y_true)\n",
        "        \n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        predicted.append(preds)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwUWGj_IKoup"
      },
      "source": [
        "true_values = np.array(true_values).reshape(-1)\n",
        "dummy = torch.FloatTensor().to(device)\n",
        "for tensor in predicted:\n",
        "    dummy = torch.cat((dummy,tensor))\n",
        "predicted = dummy.view(-1).cpu().numpy()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjxNUd7jk_-j",
        "outputId": "d440bca9-91f5-4eee-84af-71fbc05d1f81"
      },
      "source": [
        "confusion_matrix(true_values, predicted)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[59,  9],\n",
              "       [ 6, 76]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukHy0FRQBGil"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}