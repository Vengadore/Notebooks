{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "UnetSegmentation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vengadore/Notebooks/blob/master/UnetSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQDr68m233Yr"
      },
      "source": [
        "!nvidia-smi\n",
        "!rm -rf *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfBrBGeRz6i3"
      },
      "source": [
        "## Download data into local storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCrbfcQoz6i8"
      },
      "source": [
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Zfz1fk63yby"
      },
      "source": [
        "!wget \"https://correoipn-my.sharepoint.com/:u:/g/personal/ccarrillog1400_alumno_ipn_mx/ERgktnjHms9DroR01IFSAsEBGQipq3SG8sjTZUSEQuRK9Q?download=1\"\n",
        "!mv \"ERgktnjHms9DroR01IFSAsEBGQipq3SG8sjTZUSEQuRK9Q?download=1\" \"DRIVE.rar\"\n",
        "!unrar x DRIVE.rar\n",
        "!rm \"DRIVE.rar\"\n",
        "clear_output()\n",
        "print(\"DRIVE.rar Downloaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnld5s5N4E4K"
      },
      "source": [
        "!wget \"https://correoipn-my.sharepoint.com/:u:/g/personal/ccarrillog1400_alumno_ipn_mx/EeJjVR695xFMiVlTmZRPDh8BgZzjgU81MtJbNeyD3GyLQw?download=1\"\n",
        "!mv \"EeJjVR695xFMiVlTmZRPDh8BgZzjgU81MtJbNeyD3GyLQw?download=1\" STARE.zip\n",
        "!unzip STARE.zip\n",
        "!rm STARE.zip\n",
        "clear_output()\n",
        "print(\"STARE.zip Downloaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8q3J9MSz6jM"
      },
      "source": [
        "!wget \"https://correoipn-my.sharepoint.com/:u:/g/personal/ccarrillog1400_alumno_ipn_mx/ESQgnFayDEZHtMe3MEvtOxYBj_FMmJhAzjyTM8RxF9m65w?download=1\"\n",
        "!mv \"ESQgnFayDEZHtMe3MEvtOxYBj_FMmJhAzjyTM8RxF9m65w?download=1\" Drive_histogram_modification.zip\n",
        "!unzip Drive_histogram_modification.zip\n",
        "!rm Drive_histogram_modification.zip\n",
        "clear_output()\n",
        "print(\"Drive_histogram_modification.zip Downloaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKmeOIhZ4ohh"
      },
      "source": [
        "!git clone --depth 1 https://github.com/Vengadore/Segmentation_OPTOS.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM8Uchj73ycG"
      },
      "source": [
        "## Apply resize to all images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrJm9mpN7eUr"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvMjKfKM3ycO"
      },
      "source": [
        "path = \"./\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZJSlDN-z6je"
      },
      "source": [
        "#### Drive data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1ZJ-HTPz6jg"
      },
      "source": [
        "data = pd.read_csv(os.path.join(path,'training.csv'))\n",
        "data_test = pd.read_csv(os.path.join(path,'test_1stmanual.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-zGi1nm3ycU"
      },
      "source": [
        "data['Original'] = data['Original'].apply(lambda x:os.path.join(path,\"training/images/\"+x))\n",
        "data['GroundTruth'] = data['GroundTruth'].apply(lambda x:os.path.join(path,\"training/1st_manual/\"+x))\n",
        "\n",
        "data_test['Original'] = data_test['Original'].apply(lambda x:os.path.join(path,\"test/images/\"+x))\n",
        "data_test['GroundTruth'] = data_test['GroundTruth'].apply(lambda x:os.path.join(path,\"test/1st_manual/\"+x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr3i14Bjz6jn"
      },
      "source": [
        "#### Stare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hgf4PFI8vGC"
      },
      "source": [
        "Data_stare = pd.read_csv('./STARE/Data.csv')\n",
        "Data_stare['Original'] = Data_stare['Original'].apply(lambda x:os.path.join(path,\"STARE/Original/\"+x))\n",
        "Data_stare['GroundTruth'] = Data_stare['GroundTruth'].apply(lambda x:os.path.join(path,\"STARE/GroundTruth/\"+x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec1hPfyBz6js"
      },
      "source": [
        "#### Modified Drive data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrmJWiDqz6jt"
      },
      "source": [
        "Data_DriveM = pd.read_csv('./DRIVE_histogram_variations/Data.csv')\n",
        "Data_DriveM['Original'] = Data_DriveM['Original'].apply(lambda x:os.path.join(path,\"DRIVE_histogram_variations/images/\"+x))\n",
        "Data_DriveM['GroundTruth'] = Data_DriveM['GroundTruth'].apply(lambda x:os.path.join(path,\"DRIVE_histogram_variations/GroundTruth/\"+x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsdFGjZZ9twl"
      },
      "source": [
        "data = data.append(Data_stare).reset_index()\n",
        "data = data[['Original','GroundTruth']]\n",
        "data = data.append(Data_DriveM).reset_index()\n",
        "data = data[['Original','GroundTruth']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM_AL4taz6j0"
      },
      "source": [
        "## Save data csv\n",
        "data.to_csv(\"Training_data.csv\")\n",
        "data_test.to_csv(\"Test_data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcYihmGMMS2E"
      },
      "source": [
        "## Resize training images\n",
        "import os\n",
        "import cv2\n",
        "for i in data['Original']:\n",
        "  I = cv2.imread(i)\n",
        "  (M,N,C) = I.shape\n",
        "  I = cv2.resize(I,(int(N/M*584*4), 584*4),cv2.INTER_CUBIC)\n",
        "  I = cv2.imwrite(i,I)\n",
        "\n",
        "for i in data['GroundTruth']:\n",
        "  I = cv2.imread(i)\n",
        "  (M,N,C) = I.shape\n",
        "  I = cv2.resize(I,(int(N/M*584*4), 584*4),cv2.INTER_NEAREST)\n",
        "  thresh,I = cv2.threshold(I,127,255,cv2.THRESH_BINARY)\n",
        "  I = cv2.imwrite(i,I)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLTHm5cHMS_r"
      },
      "source": [
        "#Resize Test_images\n",
        "for i in data_test['Original']:\n",
        "  I = cv2.imread(i)\n",
        "  (M,N,C) = I.shape\n",
        "  I = cv2.resize(I,(int(N/M*584*4), 584*4),cv2.INTER_CUBIC)\n",
        "  I = cv2.imwrite(i,I)\n",
        "\n",
        "for i in data_test['GroundTruth']:\n",
        "  I = cv2.imread(i)\n",
        "  (M,N,C) = I.shape\n",
        "  I = cv2.resize(I,(int(N/M*584*4), 584*4),cv2.INTER_NEAREST)\n",
        "  thresh,I = cv2.threshold(I,127,255,cv2.THRESH_BINARY)\n",
        "  I = cv2.imwrite(i,I)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnxRZb7v3ycf"
      },
      "source": [
        "## Creation of dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hOCzsFm3ycf"
      },
      "source": [
        "from Segmentation_OPTOS.Tools.Generators import Patch_generator\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGgHYXOYz6kB"
      },
      "source": [
        "# Load data\n",
        "data = pd.read_csv(\"Training_data.csv\")\n",
        "data_test = pd.read_csv(\"Test_data.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMKBzUxB3ycj",
        "outputId": "c8ab84c5-4bab-42c4-f8d5-0625eb6b2164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "def x_trans(X):\n",
        "    #X = cv2.resize(X,(584*2, 565*2),cv2.INTER_CUBIC)\n",
        "    #mean,std = cv2.meanStdDev(X)\n",
        "    #_,_,C = X.shape\n",
        "    #for i in range(C):\n",
        "    #    X[:,:,i] = (X[:,:,i]-mean[i])/std[i]\n",
        "    ## Change order of channels\n",
        "    X = X.transpose(2,0,1)\n",
        "    return X\n",
        "\n",
        "def y_trans(X):\n",
        "    # Change order of channels\n",
        "    #X = cv2.resize(X,(584*3, 565*3),cv2.INTER_CUBIC)\n",
        "    X = X.transpose(2,0,1)\n",
        "    X = np.expand_dims(X[0,:,:],axis = 0)\n",
        "    return X\n",
        "\n",
        "Training_patches = Patch_generator.Generator_from_DataFrame(data,patch_size=(127,127),X = 'Original',\n",
        "                                                   y = \"GroundTruth\",n_patches = 60,transforX=x_trans,transfory=y_trans)\n",
        "\n",
        "Validation_patches = Patch_generator.Generator_from_DataFrame(data,patch_size=(127,127),X = 'Original',\n",
        "                                                   y = \"GroundTruth\",n_patches = 60,transforX=x_trans,transfory=y_trans)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "640 files found out of 640 in the DataFrame for X\n",
            "640 files found out of 640 in the DataFrame for y\n",
            "A generator object has been created with 20 per image\n",
            "640 files found out of 640 in the DataFrame for X\n",
            "640 files found out of 640 in the DataFrame for y\n",
            "A generator object has been created with 20 per image\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etkf4SYk3ycn"
      },
      "source": [
        "## Definition of the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-elx4vx3ycp"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVJTA-wn3yct"
      },
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,256,(3,3),stride = (1,1),padding=(1,1))\n",
        "        self.norm1 = nn.BatchNorm2d(256)\n",
        "        self.conv2 = nn.Conv2d(256,128,(3,3),stride = (1,1),padding=(1,1))\n",
        "        self.norm2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128,64,(3,3),stride = (1,1),padding=(1,1))\n",
        "        self.norm3 = nn.BatchNorm2d(64)\n",
        "        self.max_pool = nn.MaxPool2d((2,2))\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.norm1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.norm2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.norm3(x)\n",
        "        x = self.max_pool(x)\n",
        "        return x\n",
        "\n",
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder,self).__init__()\n",
        "        self.conv1T = nn.ConvTranspose2d(64,64,(3,3),padding=(1,1))\n",
        "        self.conv2T = nn.ConvTranspose2d(64,64,(3,3),stride=(2,2),padding=(1,1))\n",
        "        self.conv3T = nn.ConvTranspose2d(64,128,(3,3),padding=(1,1))\n",
        "        self.conv4T = nn.ConvTranspose2d(128,256,(3,3))\n",
        "        self.conv5T = nn.ConvTranspose2d(256,1,(1,1))\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.conv1T(x))\n",
        "        x = F.relu(self.conv2T(x))\n",
        "        x = F.relu(self.conv3T(x))\n",
        "        x = F.relu(self.conv4T(x))\n",
        "        x = torch.sigmoid(self.conv5T(x))\n",
        "        return x\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "    def forward(self,x):\n",
        "        x = self.encoder.forward(x)\n",
        "        x = self.decoder.forward(x)\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfq96uvv3ycx"
      },
      "source": [
        "model = Model()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UcNeRMUJWGr",
        "outputId": "1d2bdee8-17fc-4ab6-eafa-de5534e80b4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# Load Pretrained Model\n",
        "model = torch.load(\"./Modelo_seg(1).ph\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-bf8ba9e11fed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load Pretrained Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Modelo_seg.ph\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Modelo_seg.ph'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M24FXtgq3yc2"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVQAlSzj3yc6"
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD4OK4Ce3yc9"
      },
      "source": [
        "## Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLk1gLIP3yc-"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa9-n3Bh3ydB",
        "outputId": "a549e497-0e7d-4d00-f3c0-63796ff80208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "training_accuracy = []\n",
        "training_loss = []\n",
        "\n",
        "for epoch in range(100):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    ## Training loop for epoch\n",
        "    progress_bar = pbar = tqdm(range(len(data)),ncols = 150)\n",
        "    epoch_acc = 0.0\n",
        "    for i in progress_bar:\n",
        "        (X,y) = next(Training_patches)\n",
        "        X = torch.FloatTensor(X).to(device)\n",
        "        y = torch.FloatTensor(y).to(device)\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward + backward + optimize\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Accuracy\n",
        "        step_acc = torch.true_divide(torch.sum(outputs.gt(0.5) == y.gt(0.5)),y.view(-1).shape[0])\n",
        "        epoch_acc += step_acc\n",
        "        # print statistics\n",
        "        step_loss = loss.item()\n",
        "        running_loss += step_loss\n",
        "        progress_bar.set_description(f\"Accuracy: {step_acc:.4f}, Loss: {step_loss:.4f}\")\n",
        "    print(f\"Epoch:{epoch+1} Loss:{running_loss/(i+1):.5f} Accuracy:{epoch_acc/(i+1):.5f} \")\n",
        "    training_accuracy.append(epoch_acc/(i+1))\n",
        "    training_loss.append(running_loss/(i+1))\n",
        "\n",
        "print('Training DONE!')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.933, Loss: 0.192: 100%|███████████████████████████████| 640/640 [11:25<00:00,  1.07s/it]\n",
            "  0%|                                                                       | 0/640 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:1 Loss:0.3124554968322627 Accuracy:0.895177960395813 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.908, Loss: 0.240:  92%|████████████████████████████▋  | 592/640 [10:33<00:50,  1.05s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7c59ddfc1798>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#Accuracy += np.sum(np.max(y.detach().cpu().numpy()) == np.max(outputs.detach().cpu().numpy()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy: {acc:.3f}, Loss: {l:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF8pDOJX3ydJ"
      },
      "source": [
        "torch.save(model,\"Modelo_seg.ph\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzNKHOpI3ydN"
      },
      "source": [
        "model = torch.load('Modelo_seg.ph')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VLbH1r1GM_W"
      },
      "source": [
        "from Segmentation_OPTOS.Tools.Generators.Patch_generator import Image2Generator,Generator2ImagePT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIRW_tT_fXc1"
      },
      "source": [
        "I = cv2.imread(data_test['Original'].iloc[-2])\n",
        "I.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPBuiRaw3ydX"
      },
      "source": [
        "Test_generator = Image2Generator(I,patch_size=[127,127],batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCvfW8pp3ydb"
      },
      "source": [
        "New_I = Generator2ImagePT(model,Test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OdduWXb3ydf"
      },
      "source": [
        "New_I.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hz_aHSye9ml"
      },
      "source": [
        "New_I.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yr-cGsO3ydh"
      },
      "source": [
        "plt.imshow(New_I>0.6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP7jcqr7Govh"
      },
      "source": [
        "plt.imsave(\"Example.jpeg\",New_I)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iICs4G13ydl"
      },
      "source": [
        "plt.imshow(I)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzLoCDTY3ydo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}