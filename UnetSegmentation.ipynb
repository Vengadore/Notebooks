{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "UnetSegmentation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vengadore/Notebooks/blob/master/UnetSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQDr68m233Yr"
      },
      "source": [
        "!nvidia-smi\n",
        "!rm -rf *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfBrBGeRz6i3"
      },
      "source": [
        "## Download data into local storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCrbfcQoz6i8"
      },
      "source": [
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Zfz1fk63yby"
      },
      "source": [
        "!wget \"https://correoipn-my.sharepoint.com/:u:/g/personal/ccarrillog1400_alumno_ipn_mx/ERgktnjHms9DroR01IFSAsEBGQipq3SG8sjTZUSEQuRK9Q?download=1\"\n",
        "!mv \"ERgktnjHms9DroR01IFSAsEBGQipq3SG8sjTZUSEQuRK9Q?download=1\" \"DRIVE.rar\"\n",
        "!unrar x DRIVE.rar\n",
        "!rm \"DRIVE.rar\"\n",
        "clear_output()\n",
        "print(\"DRIVE.rar Downloaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnld5s5N4E4K"
      },
      "source": [
        "!wget \"https://correoipn-my.sharepoint.com/:u:/g/personal/ccarrillog1400_alumno_ipn_mx/EeJjVR695xFMiVlTmZRPDh8BgZzjgU81MtJbNeyD3GyLQw?download=1\"\n",
        "!mv \"EeJjVR695xFMiVlTmZRPDh8BgZzjgU81MtJbNeyD3GyLQw?download=1\" STARE.zip\n",
        "!unzip STARE.zip\n",
        "!rm STARE.zip\n",
        "clear_output()\n",
        "print(\"STARE.zip Downloaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8q3J9MSz6jM"
      },
      "source": [
        "!wget \"https://correoipn-my.sharepoint.com/:u:/g/personal/ccarrillog1400_alumno_ipn_mx/ESQgnFayDEZHtMe3MEvtOxYBj_FMmJhAzjyTM8RxF9m65w?download=1\"\n",
        "!mv \"ESQgnFayDEZHtMe3MEvtOxYBj_FMmJhAzjyTM8RxF9m65w?download=1\" Drive_histogram_modification.zip\n",
        "!unzip Drive_histogram_modification.zip\n",
        "!rm Drive_histogram_modification.zip\n",
        "clear_output()\n",
        "print(\"Drive_histogram_modification.zip Downloaded\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKmeOIhZ4ohh"
      },
      "source": [
        "!git clone --depth 1 https://github.com/Vengadore/Segmentation_OPTOS.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM8Uchj73ycG"
      },
      "source": [
        "## Apply resize to all images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrJm9mpN7eUr"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvMjKfKM3ycO"
      },
      "source": [
        "path = \"./\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZJSlDN-z6je"
      },
      "source": [
        "#### Drive data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1ZJ-HTPz6jg"
      },
      "source": [
        "data = pd.read_csv(os.path.join(path,'training.csv'))\n",
        "data_test = pd.read_csv(os.path.join(path,'test_1stmanual.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-zGi1nm3ycU"
      },
      "source": [
        "data['Original'] = data['Original'].apply(lambda x:os.path.join(path,\"training/images/\"+x))\n",
        "data['GroundTruth'] = data['GroundTruth'].apply(lambda x:os.path.join(path,\"training/1st_manual/\"+x))\n",
        "\n",
        "data_test['Original'] = data_test['Original'].apply(lambda x:os.path.join(path,\"test/images/\"+x))\n",
        "data_test['GroundTruth'] = data_test['GroundTruth'].apply(lambda x:os.path.join(path,\"test/1st_manual/\"+x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr3i14Bjz6jn"
      },
      "source": [
        "#### Stare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hgf4PFI8vGC"
      },
      "source": [
        "Data_stare = pd.read_csv('./STARE/Data.csv')\n",
        "Data_stare['Original'] = Data_stare['Original'].apply(lambda x:os.path.join(path,\"STARE/Original/\"+x))\n",
        "Data_stare['GroundTruth'] = Data_stare['GroundTruth'].apply(lambda x:os.path.join(path,\"STARE/GroundTruth/\"+x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec1hPfyBz6js"
      },
      "source": [
        "#### Modified Drive data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrmJWiDqz6jt"
      },
      "source": [
        "Data_DriveM = pd.read_csv('./DRIVE_histogram_variations/Data.csv')\n",
        "Data_DriveM['Original'] = Data_DriveM['Original'].apply(lambda x:os.path.join(path,\"DRIVE_histogram_variations/images/\"+x))\n",
        "Data_DriveM['GroundTruth'] = Data_DriveM['GroundTruth'].apply(lambda x:os.path.join(path,\"DRIVE_histogram_variations/GroundTruth/\"+x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsdFGjZZ9twl"
      },
      "source": [
        "data = data.append(Data_stare).reset_index()\n",
        "data = data[['Original','GroundTruth']]\n",
        "data = data.append(Data_DriveM).reset_index()\n",
        "data = data[['Original','GroundTruth']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM_AL4taz6j0"
      },
      "source": [
        "## Save data csv\n",
        "data.to_csv(\"Training_data.csv\")\n",
        "data_test.to_csv(\"Test_data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcYihmGMMS2E"
      },
      "source": [
        "## Resize training images\n",
        "import os\n",
        "import cv2\n",
        "for i in data['Original']:\n",
        "  I = cv2.imread(i)\n",
        "  (M,N,C) = I.shape\n",
        "  I = cv2.resize(I,(int(N/M*584*4), 584*4),cv2.INTER_CUBIC)\n",
        "  I = cv2.imwrite(i,I)\n",
        "\n",
        "for i in data['GroundTruth']:\n",
        "  I = cv2.imread(i)\n",
        "  (M,N,C) = I.shape\n",
        "  I = cv2.resize(I,(int(N/M*584*4), 584*4),cv2.INTER_NEAREST)\n",
        "  thresh,I = cv2.threshold(I,127,255,cv2.THRESH_BINARY)\n",
        "  I = cv2.imwrite(i,I)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLTHm5cHMS_r"
      },
      "source": [
        "#Resize Test_images\n",
        "for i in data_test['Original']:\n",
        "  I = cv2.imread(i)\n",
        "  (M,N,C) = I.shape\n",
        "  I = cv2.resize(I,(int(N/M*584*4), 584*4),cv2.INTER_CUBIC)\n",
        "  I = cv2.imwrite(i,I)\n",
        "\n",
        "for i in data_test['GroundTruth']:\n",
        "  I = cv2.imread(i)\n",
        "  (M,N,C) = I.shape\n",
        "  I = cv2.resize(I,(int(N/M*584*4), 584*4),cv2.INTER_NEAREST)\n",
        "  thresh,I = cv2.threshold(I,127,255,cv2.THRESH_BINARY)\n",
        "  I = cv2.imwrite(i,I)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnxRZb7v3ycf"
      },
      "source": [
        "## Creation of dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hOCzsFm3ycf"
      },
      "source": [
        "from Segmentation_OPTOS.Tools.Generators import Patch_generator\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGgHYXOYz6kB"
      },
      "source": [
        "# Load data\n",
        "data = pd.read_csv(\"Training_data.csv\")\n",
        "data_test = pd.read_csv(\"Test_data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMKBzUxB3ycj"
      },
      "source": [
        "def x_trans(X):\n",
        "    #X = cv2.resize(X,(584*2, 565*2),cv2.INTER_CUBIC)\n",
        "    #mean,std = cv2.meanStdDev(X)\n",
        "    #_,_,C = X.shape\n",
        "    #for i in range(C):\n",
        "    #    X[:,:,i] = (X[:,:,i]-mean[i])/std[i]\n",
        "    ## Change order of channels\n",
        "    X = X.transpose(2,0,1)\n",
        "    return X\n",
        "\n",
        "def y_trans(X):\n",
        "    # Change order of channels\n",
        "    #X = cv2.resize(X,(584*3, 565*3),cv2.INTER_CUBIC)\n",
        "    X = X.transpose(2,0,1)\n",
        "    X = np.expand_dims(X[0,:,:],axis = 0)\n",
        "    return X\n",
        "\n",
        "Training_patches = Patch_generator.Generator_from_DataFrame(data,patch_size=(127,127),X = 'Original',\n",
        "                                                   y = \"GroundTruth\",n_patches = 20,transforX=x_trans,transfory=y_trans)\n",
        "\n",
        "Validation_patches = Patch_generator.Generator_from_DataFrame(data,patch_size=(127,127),X = 'Original',\n",
        "                                                   y = \"GroundTruth\",n_patches = 20,transforX=x_trans,transfory=y_trans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etkf4SYk3ycn"
      },
      "source": [
        "## Definition of the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-elx4vx3ycp"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVJTA-wn3yct"
      },
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,256,(3,3),stride = (1,1),padding=(1,1))\n",
        "        self.norm1 = nn.BatchNorm2d(256)\n",
        "        self.conv2 = nn.Conv2d(256,128,(3,3),stride = (1,1),padding=(1,1))\n",
        "        self.norm2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128,64,(3,3),stride = (1,1),padding=(1,1))\n",
        "        self.norm3 = nn.BatchNorm2d(64)\n",
        "        self.max_pool = nn.MaxPool2d((2,2))\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.norm1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.norm2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.norm3(x)\n",
        "        x = self.max_pool(x)\n",
        "        return x\n",
        "\n",
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder,self).__init__()\n",
        "        self.conv1T = nn.ConvTranspose2d(64,64,(3,3),padding=(1,1))\n",
        "        self.conv2T = nn.ConvTranspose2d(64,64,(3,3),stride=(2,2),padding=(1,1))\n",
        "        self.conv3T = nn.ConvTranspose2d(64,128,(3,3),padding=(1,1))\n",
        "        self.conv4T = nn.ConvTranspose2d(128,256,(3,3))\n",
        "        self.conv5T = nn.ConvTranspose2d(256,1,(1,1))\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.conv1T(x))\n",
        "        x = F.relu(self.conv2T(x))\n",
        "        x = F.relu(self.conv3T(x))\n",
        "        x = F.relu(self.conv4T(x))\n",
        "        x = torch.sigmoid(self.conv5T(x))\n",
        "        return x\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "    def forward(self,x):\n",
        "        x = self.encoder.forward(x)\n",
        "        x = self.decoder.forward(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfq96uvv3ycx"
      },
      "source": [
        "model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UcNeRMUJWGr"
      },
      "source": [
        "# Load Pretrained Model\n",
        "model = torch.load(\"./Modelo_seg.ph\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M24FXtgq3yc2"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVQAlSzj3yc6"
      },
      "source": [
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD4OK4Ce3yc9"
      },
      "source": [
        "## Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLk1gLIP3yc-"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.000005)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa9-n3Bh3ydB"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in range(200):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    ## Training loop for epoch\n",
        "    epoch_acc = 0.0\n",
        "    for i in tqdm(range(len(data))):\n",
        "        (X,y) = next(Training_patches)\n",
        "        X = torch.FloatTensor(X).to(device)\n",
        "        y = torch.FloatTensor(y).to(device)\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward + backward + optimize\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs, y)\n",
        "        epoch_acc += torch.true_divide(torch.sum(outputs.gt(0.5) == y.gt(0.5)),y.view(-1).shape[0])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Accuracy\n",
        "        #Accuracy += np.sum(np.max(y.detach().cpu().numpy()) == np.max(outputs.detach().cpu().numpy()))\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch:{epoch+1} Loss:{running_loss/(i+1)} Accuracy:{epoch_acc/(i+1)} \")#Accuracy = {Accuracy/6350400}\")\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF8pDOJX3ydJ"
      },
      "source": [
        "torch.save(model,\"Modelo_seg.ph\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzNKHOpI3ydN"
      },
      "source": [
        "model = torch.load('Modelo_seg.ph')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VLbH1r1GM_W"
      },
      "source": [
        "from Segmentation_OPTOS.Tools.Generators.Patch_generator import Image2Generator,Generator2ImagePT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIRW_tT_fXc1"
      },
      "source": [
        "I = cv2.imread(data_test['Original'].iloc[-2])\n",
        "I.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPBuiRaw3ydX"
      },
      "source": [
        "Test_generator = Image2Generator(I,patch_size=[127,127],batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCvfW8pp3ydb"
      },
      "source": [
        "New_I = Generator2ImagePT(model,Test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OdduWXb3ydf"
      },
      "source": [
        "New_I.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hz_aHSye9ml"
      },
      "source": [
        "New_I.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yr-cGsO3ydh"
      },
      "source": [
        "plt.imshow(New_I>0.6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP7jcqr7Govh"
      },
      "source": [
        "plt.imsave(\"Example.jpeg\",New_I)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iICs4G13ydl"
      },
      "source": [
        "plt.imshow(I)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzLoCDTY3ydo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}