{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training optic Discs in Efficientnet.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d69844859b44bcfb7ea0010b46313ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3eddba334e8e41b28e3f0ac8a300689c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f8e93a0af3064c91a0947fedf63811b7",
              "IPY_MODEL_56948f0137af47e2aaefbb1ece6938eb"
            ]
          }
        },
        "3eddba334e8e41b28e3f0ac8a300689c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8e93a0af3064c91a0947fedf63811b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6d6ee488c4374663834f20cd8b5d579f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 266860719,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 266860719,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_faedbc8f3b58448884e840d5cc9c1732"
          }
        },
        "56948f0137af47e2aaefbb1ece6938eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_32162a376c76460eb1b22427704a2c9f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 254M/254M [00:05&lt;00:00, 53.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89b463812e21462392e0dd88d770d89b"
          }
        },
        "6d6ee488c4374663834f20cd8b5d579f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "faedbc8f3b58448884e840d5cc9c1732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32162a376c76460eb1b22427704a2c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89b463812e21462392e0dd88d770d89b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vengadore/Notebooks/blob/master/Training_optic_Discs_in_Efficientnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVm5Ats_YVEZ"
      },
      "source": [
        "# Diabetic Retinopathy Detection\n",
        "\n",
        "Kaggle has a large competition of Diabetic Retinopathy detection which can be found here:\n",
        "https://www.kaggle.com/c/diabetic-retinopathy-detection/\n",
        "\n",
        "Their dataset consists in 35126 images labeled from 0 to 4 according to the degree of Retinopathy.\n",
        "An analysis of the data is provided in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QABUN5czaGrr",
        "outputId": "a345b8f3-9289-4496-bcb2-1a5dcc483126"
      },
      "source": [
        "!rm -rf sample_data\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Feb 15 13:34:47 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrtmQaiBbcy5"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKfg7kcTbb4h"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install efficientnet_pytorch\n",
        "clear_output(wait=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO_cEyuIeDjq"
      },
      "source": [
        "## Load data from local drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWk0Ox2ueHNB",
        "outputId": "a8035b86-84c9-4df8-d936-f63c93252237"
      },
      "source": [
        "!wget -O File.zip \"https://correoipn-my.sharepoint.com/:u:/g/personal/ccarrillog1400_alumno_ipn_mx/ETdcB8GscyBAkhUFvNMzpoUBLLgg7ej9Q3t4rK_bR8ngSA?download=1\"\n",
        "!unzip File.zip\n",
        "!rm File.zip\n",
        "clear_output(wait=False)\n",
        "print(\"Data Downloaded\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUCY7oQLorC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24987142-82fd-441a-9f04-33e1bc052d02"
      },
      "source": [
        "!rm checkpoint*"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'checkpoint*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dNqkjvcUetED",
        "outputId": "31f04326-9f12-4b85-ea92-380e26f919db"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "Bad =  pd.DataFrame({\"imageFilename\":[os.path.join(\"./OpticDiscs/Neovessels\",File) for File in os.listdir(\"./OpticDiscs/Neovessels\") if \".jpeg\" in File]})\n",
        "Good = pd.DataFrame({\"imageFilename\":[os.path.join(\"./OpticDiscs/Good images\",File) for File in os.listdir(\"./OpticDiscs/Good images\") if \".jpeg\" in File]}).sample(len(Bad),random_state = 42)\n",
        "\n",
        "data = pd.concat((Good,Bad),axis = 0)\n",
        "data.head()\n",
        "data['class'] = data['imageFilename'].apply(lambda x : 1 if \"Good\" in x else 0)\n",
        "data = data.reset_index()\n",
        "data = data[['imageFilename','class']]\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imageFilename</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./OpticDiscs/Good images/29421_left.jpeg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./OpticDiscs/Good images/39934_left.jpeg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./OpticDiscs/Good images/26612_right.jpeg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./OpticDiscs/Good images/23548_right.jpeg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./OpticDiscs/Good images/6541_left.jpeg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               imageFilename  class\n",
              "0   ./OpticDiscs/Good images/29421_left.jpeg      1\n",
              "1   ./OpticDiscs/Good images/39934_left.jpeg      1\n",
              "2  ./OpticDiscs/Good images/26612_right.jpeg      1\n",
              "3  ./OpticDiscs/Good images/23548_right.jpeg      1\n",
              "4    ./OpticDiscs/Good images/6541_left.jpeg      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3N0Ue5MCvlk",
        "outputId": "12c7819a-9f73-41a5-8d22-83f424b08fa7"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "374"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deKSOu-Kd8Yk"
      },
      "source": [
        "#### Split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w3TUlaqd7qi"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['imageFilename'], data['class'], test_size=0.30, random_state=65)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3hQn37YfvsA",
        "outputId": "ae74fd20-3682-4c47-f971-5e8fa9301739"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    139\n",
              "1    122\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVIy3dn7eKFq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1d9f0c1f-d611-4406-bb19-b8a4a449115d"
      },
      "source": [
        "test_data = pd.DataFrame({'image':X_test,'class':y_test})\n",
        "test_data['image'] = test_data['image'].apply(lambda x : x.split('/')[-1])\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>10785_left.jpeg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>38518_left.jpeg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>16413_left.jpeg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>2916_left.jpeg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>1772_left.jpeg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               image  class\n",
              "278  10785_left.jpeg      0\n",
              "366  38518_left.jpeg      0\n",
              "287  16413_left.jpeg      0\n",
              "202   2916_left.jpeg      0\n",
              "146   1772_left.jpeg      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YsYT7VjerXq"
      },
      "source": [
        "test_data.to_csv('test_data.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPh3qDdIdkHh"
      },
      "source": [
        "## Definition of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "0d69844859b44bcfb7ea0010b46313ee",
            "3eddba334e8e41b28e3f0ac8a300689c",
            "f8e93a0af3064c91a0947fedf63811b7",
            "56948f0137af47e2aaefbb1ece6938eb",
            "6d6ee488c4374663834f20cd8b5d579f",
            "faedbc8f3b58448884e840d5cc9c1732",
            "32162a376c76460eb1b22427704a2c9f",
            "89b463812e21462392e0dd88d770d89b"
          ]
        },
        "id": "Z-FUmuJidoy3",
        "outputId": "804bc40e-aab4-48e1-971b-604611b1d15b"
      },
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "import torch\n",
        "network_name = 'efficientnet-b7'\n",
        "model = EfficientNet.from_pretrained(network_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b7-dcc49843.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d69844859b44bcfb7ea0010b46313ee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=266860719.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded pretrained weights for efficientnet-b7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drpW39Qwj3l9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595afd95-efa5-41f7-b749-65c8679eacef"
      },
      "source": [
        "model._fc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=2560, out_features=1000, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu_aoH7-tBsT"
      },
      "source": [
        "## Change efficientnet final layer\n",
        "model._fc = torch.nn.Linear(in_features=2560,out_features=2,bias = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNns-LOy6TrK",
        "outputId": "377822ec-6a1f-443e-d22a-a47f199374b4"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "count_parameters(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63792082"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BR_Hs12gAqx"
      },
      "source": [
        "from torchvision.transforms import Resize,ToTensor,Compose,Normalize\n",
        "from torchvision.transforms import RandomHorizontalFlip,RandomVerticalFlip,RandomRotation,ColorJitter\n",
        "from PIL import Image\n",
        "\n",
        "transforms = Compose([RandomHorizontalFlip(),RandomVerticalFlip(),RandomRotation(180),ColorJitter(0.5,0.5,0.5)]) # Transformations for the training images\n",
        "\n",
        "composed = Compose([Resize(600), # Resize to a fit size for efficientnet\n",
        "                    ToTensor(),  # Convert into sensor\n",
        "                    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # Normalize image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWg1p7EQtqVZ"
      },
      "source": [
        "### Training parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiT-MlPutsZR"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device);\n",
        "seed = 17\n",
        "torch.manual_seed(seed)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJWflI4JoVRW",
        "outputId": "4086cecb-164b-4e77-9437-b45ec9a8fe2e"
      },
      "source": [
        "try:\n",
        "    model = torch.load('./checkpoint_b0_11.ph', map_location=device)\n",
        "except:\n",
        "    print(\"No Checkpoint loaded\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No Checkpoint loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcTzzyr5uUdr"
      },
      "source": [
        "classes = {0:[0,0,0,0,1],\n",
        "           1:[0,0,0,1,0],\n",
        "           2:[0,0,1,0,0],\n",
        "           3:[0,1,0,0,0],\n",
        "           4:[1,0,0,0,0]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkvlQWRQtjXo",
        "outputId": "1d29e2ff-07d8-4cce-c6f6-b7e0f1d8f326"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "random.seed(seed)\n",
        "\n",
        "epochs = 40\n",
        "batch_size = 1  # I will use batch size of 1 to keep the ratio of each image\n",
        "\n",
        "TRAINING_acc = []\n",
        "VALIDATION_acc = []\n",
        "BEST_val_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    indexes = [idx for idx in range(len(X_train))]\n",
        "    pbar = tqdm( range(len(X_train)//batch_size),ncols = 100)\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    t = 0\n",
        "\n",
        "    for step in pbar:\n",
        "        # Load data\n",
        "        idx = random.sample(indexes,batch_size)\n",
        "        X = X_train.iloc[idx]\n",
        "        y = y_train.iloc[idx]\n",
        "\n",
        "        # Remove indexes\n",
        "        [indexes.remove(i) for i in idx]\n",
        "\n",
        "        # Load images\n",
        "        try:\n",
        "            images = [Image.open(File) for File in X]\n",
        "        except:\n",
        "            continue\n",
        "        # Load y_true\n",
        "        y_true = torch.LongTensor([c for c in y]).to(device)\n",
        "        \n",
        "        # Convert images to tensor\n",
        "        x_batch = torch.FloatTensor().to(device)\n",
        "        for image in images:\n",
        "            P = transforms(image)\n",
        "            P = composed(P).unsqueeze(0).to(device)\n",
        "            x_batch = torch.cat((x_batch,P))\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(x_batch)\n",
        "        loss = criterion(outputs, y_true)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        t += batch_size\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_acc += torch.sum(preds == y_true).cpu().detach().numpy()\n",
        "        acc = torch.sum(preds == y_true).cpu().detach().numpy()/batch_size;\n",
        "        pbar.set_description(\"Epoch: {} Accuracy: {:0.5f} Loss: {:0.5f} \".format(epoch+1,running_acc/t,loss.item()))\n",
        "    #Validation\n",
        "    TRAINING_acc.append(running_acc/t)\n",
        "    val_acc = 0.0\n",
        "    val_loss = 0.0\n",
        "    t = 0\n",
        "    for point in range(len(X_test)//batch_size):\n",
        "        with torch.no_grad():\n",
        "\n",
        "            X = X_test.iloc[point*batch_size:(point+1)*batch_size]\n",
        "            y = y_test.iloc[point*batch_size:(point+1)*batch_size]\n",
        "\n",
        "\n",
        "            # Load images\n",
        "            try:\n",
        "                images = [Image.open(File) for File in X]\n",
        "            except:\n",
        "                continue\n",
        "            # Load y_true\n",
        "            y_true = torch.LongTensor([c for c in y]).to(device)\n",
        "            \n",
        "            # Convert images to tensor\n",
        "            x_batch = torch.FloatTensor().to(device)\n",
        "            for image in images:\n",
        "                P = composed(image).unsqueeze(0).to(device)\n",
        "                x_batch = torch.cat((x_batch,P))\n",
        "\n",
        "            \n",
        "            outputs = model(x_batch)\n",
        "            loss = criterion(outputs, y_true)\n",
        "            val_loss += loss.item()\n",
        "            t += batch_size\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_acc += torch.sum(preds == y_true).cpu().detach().numpy()\n",
        "    VALIDATION_acc.append(val_acc/t)\n",
        "    print(\"Validation -- Accuracy: {:0.5f} Loss: {:0.5f} \\n\".format(val_acc/t,loss.item()))\n",
        "    if val_acc/t > BEST_val_acc:\n",
        "        try:\n",
        "            torch.save(model,\"/content/checkpoint_{}_{}_{:0.5f}.ph\".format(network_name,epoch+1,val_acc/t))\n",
        "            BEST_val_acc = val_acc/t\n",
        "        except:\n",
        "            continue"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 Accuracy: 0.52679 Loss: 0.61958 : 100%|██████████████████| 224/224 [02:10<00:00,  1.71it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.49333 Loss: 0.69054 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2 Accuracy: 0.57143 Loss: 0.63318 : 100%|██████████████████| 224/224 [02:14<00:00,  1.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.52667 Loss: 0.69976 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3 Accuracy: 0.64732 Loss: 0.68605 : 100%|██████████████████| 224/224 [02:14<00:00,  1.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.68000 Loss: 0.71321 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4 Accuracy: 0.79464 Loss: 0.52265 : 100%|██████████████████| 224/224 [02:14<00:00,  1.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.73333 Loss: 0.72225 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5 Accuracy: 0.76786 Loss: 0.41495 : 100%|██████████████████| 224/224 [02:15<00:00,  1.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.77333 Loss: 0.62577 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6 Accuracy: 0.83482 Loss: 0.21943 : 100%|██████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.77333 Loss: 0.57138 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7 Accuracy: 0.84375 Loss: 0.12718 : 100%|██████████████████| 224/224 [02:14<00:00,  1.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.81333 Loss: 0.55777 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8 Accuracy: 0.88393 Loss: 0.51771 : 100%|██████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.79333 Loss: 0.51819 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9 Accuracy: 0.92411 Loss: 0.09734 : 100%|██████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.80667 Loss: 0.45732 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10 Accuracy: 0.91071 Loss: 0.09804 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.78000 Loss: 0.62927 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11 Accuracy: 0.92411 Loss: 0.13069 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.81333 Loss: 0.24124 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12 Accuracy: 0.94643 Loss: 0.03690 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.84000 Loss: 0.18580 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13 Accuracy: 0.95982 Loss: 1.48233 : 100%|█████████████████| 224/224 [02:14<00:00,  1.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.86000 Loss: 0.11088 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14 Accuracy: 0.92857 Loss: 0.02500 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.84667 Loss: 0.08251 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15 Accuracy: 0.97768 Loss: 0.00605 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.84667 Loss: 0.09547 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 16 Accuracy: 0.95089 Loss: 0.00754 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.83333 Loss: 0.08229 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 17 Accuracy: 0.98661 Loss: 0.00743 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.84000 Loss: 0.03850 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 18 Accuracy: 0.96429 Loss: 0.02067 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.85333 Loss: 0.06447 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 19 Accuracy: 0.98214 Loss: 0.01205 : 100%|█████████████████| 224/224 [02:14<00:00,  1.67it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.82000 Loss: 0.13331 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 20 Accuracy: 0.96429 Loss: 0.00901 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.79333 Loss: 0.09622 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 21 Accuracy: 0.97321 Loss: 0.00283 : 100%|█████████████████| 224/224 [02:15<00:00,  1.65it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.81333 Loss: 0.14558 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 22 Accuracy: 0.96429 Loss: 1.48434 : 100%|█████████████████| 224/224 [02:15<00:00,  1.65it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.86000 Loss: 0.13570 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 23 Accuracy: 0.97321 Loss: 0.01128 : 100%|█████████████████| 224/224 [02:15<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.82000 Loss: 0.22402 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 24 Accuracy: 0.99554 Loss: 0.00904 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.86667 Loss: 0.12160 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 25 Accuracy: 0.98661 Loss: 0.09890 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.85333 Loss: 0.07932 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 26 Accuracy: 0.95982 Loss: 0.28495 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.84667 Loss: 0.11000 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 27 Accuracy: 0.98661 Loss: 0.00295 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.84000 Loss: 0.19608 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 28 Accuracy: 0.96429 Loss: 0.18290 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.84000 Loss: 0.12293 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 29 Accuracy: 0.98661 Loss: 0.00392 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.84667 Loss: 0.25731 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 30 Accuracy: 0.99554 Loss: 0.00982 : 100%|█████████████████| 224/224 [02:15<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.84667 Loss: 0.14188 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 31 Accuracy: 0.97768 Loss: 0.00226 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.78667 Loss: 1.24738 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 32 Accuracy: 0.98214 Loss: 0.02120 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.85333 Loss: 0.06453 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 33 Accuracy: 0.99554 Loss: 0.00150 : 100%|█████████████████| 224/224 [02:15<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.84667 Loss: 0.08938 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 34 Accuracy: 0.98661 Loss: 0.00135 : 100%|█████████████████| 224/224 [02:15<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.86667 Loss: 0.15696 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 35 Accuracy: 0.98661 Loss: 0.00289 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.83333 Loss: 0.07350 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 36 Accuracy: 0.99107 Loss: 0.00722 : 100%|█████████████████| 224/224 [02:15<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.85333 Loss: 0.04381 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 37 Accuracy: 0.99554 Loss: 0.00727 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.85333 Loss: 0.10606 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 38 Accuracy: 0.99554 Loss: 0.02107 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n",
            "  0%|                                                                       | 0/224 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.85333 Loss: 0.06753 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 39 Accuracy: 0.98214 Loss: 0.00365 : 100%|█████████████████| 224/224 [02:15<00:00,  1.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.87333 Loss: 0.07856 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 40 Accuracy: 1.00000 Loss: 0.01116 : 100%|█████████████████| 224/224 [02:14<00:00,  1.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation -- Accuracy: 0.87333 Loss: 0.04519 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpupTOMPlWD8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "11ca0ff9-650f-4e3b-d344-f2016ee05778"
      },
      "source": [
        "history = pd.DataFrame({\"Train\":TRAINING_acc,\"Validation\":VALIDATION_acc})\n",
        "history.plot()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8e7884a1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PV_uLtQnaO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07eab51e-6040-4bbb-e475-b72c2f7c5eba"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint_efficientnet-b7_1_0.49333.ph\n",
            "checkpoint_efficientnet-b7_12_0.84000.ph\n",
            "checkpoint_efficientnet-b7_13_0.86000.ph\n",
            "checkpoint_efficientnet-b7_2_0.52667.ph\n",
            "checkpoint_efficientnet-b7_24_0.86667.ph\n",
            "checkpoint_efficientnet-b7_3_0.68000.ph\n",
            "checkpoint_efficientnet-b7_39_0.87333.ph\n",
            "checkpoint_efficientnet-b7_4_0.73333.ph\n",
            "checkpoint_efficientnet-b7_5_0.77333.ph\n",
            "checkpoint_efficientnet-b7_7_0.81333.ph\n",
            "OpticDiscs\n",
            "test_data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VumKHi2Snf4F"
      },
      "source": [
        "torch.save(model,\"checkpoint.ph\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYI16QYGyqLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74b7ea9-2755-42b6-c1ee-e91eb39d233f"
      },
      "source": [
        "for c in y:\n",
        "  print(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv2fODvHJlIM"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ennB90UVVmb"
      },
      "source": [
        "model = torch.load('checkpoint_efficientnet-b7_39_0.87333.ph')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLd2H4FrJnXo"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6nVWUqYJoDh"
      },
      "source": [
        "predicted = []\n",
        "true_values = []\n",
        "for point in range(len(X_test)//batch_size):\n",
        "    with torch.no_grad():\n",
        "\n",
        "        X = X_test.iloc[point*batch_size:(point+1)*batch_size]\n",
        "        y = y_test.iloc[point*batch_size:(point+1)*batch_size]\n",
        "\n",
        "        true_values.append(y.values)\n",
        "        # Load images\n",
        "        try:\n",
        "            images = [Image.open(File) for File in X]\n",
        "        except:\n",
        "            continue\n",
        "        # Load y_true\n",
        "        y_true = torch.LongTensor([c for c in y]).to(device)\n",
        "        \n",
        "        # Convert images to tensor\n",
        "        x_batch = torch.FloatTensor().to(device)\n",
        "        for image in images:\n",
        "            P = composed(image).unsqueeze(0).to(device)\n",
        "            x_batch = torch.cat((x_batch,P))\n",
        "\n",
        "        \n",
        "        outputs = model(x_batch)\n",
        "        loss = criterion(outputs, y_true)\n",
        "        \n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        predicted.append(preds)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwUWGj_IKoup"
      },
      "source": [
        "true_values = np.array(true_values).reshape(-1)\n",
        "dummy = torch.FloatTensor().to(device)\n",
        "for tensor in predicted:\n",
        "    dummy = torch.cat((dummy,tensor))\n",
        "predicted = dummy.view(-1).cpu().numpy()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjxNUd7jk_-j",
        "outputId": "f460ad09-fee0-4855-cbeb-ab55982c7110"
      },
      "source": [
        "confusion_matrix(true_values, predicted)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[56, 12],\n",
              "       [11, 71]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2ffO6tWbHTw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}